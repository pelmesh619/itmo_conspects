\clearpage

\section{X. Программа экзамена в 2024/2025}

\begin{enumerate}
    \item Пространство элементарных исходов. Случайные события. Операции над событиями.

    \hyperlink{spaceofelementaryoutcomes}{Пространство элементарных исходов}: Пространством элементарных исходов $\Omega$ называется множество, содержащее все возможные исходы
    экспериментов, из которых при испытании происходит ровно один. Элементы этого множества называются
    элементарными исходами и обозначаются $\omega$

    \hyperlink{randomeventdefinition}{Случайное событие}: Случайными событиями называется подмножество $A \subset \Omega$. События $A$ наступают, если произошел один из
    элементарных исходов из множества $A$

    \hyperlink{randomeventoperations}{Операции над событиями}: Суммой $A + B$ называется событие, состоящее в том, что произошло события $A$ или событие $B$ (хотя бы одно из них)

    Произведением $A \cdot B$ называется событие, состоящее в том, что произошло событие $A$ и событие $B$ (оба из них)

    Противоположным $A$ событием называется событие $\overline{A}$, состоящее в том, что событие $A$ не произошло

    Дополнение (разность) $A \setminus B$ называется событие $A \cdot \overline{B}$

    События $A$ и $B$ называются несовместными, если их произведение - пустое множество
    (не могут произойти одновременно при одной эксперименте)

    События $A$ влечет события $B$, если $A \subset B$ (если наступает $A$, то наступит $B$)

    \item Статистическое определение вероятности. Классическое определение вероятности.

    \hyperlink{statisticaldefinitionofprobability}{Статистическое определение вероятности}: Пусть проводится $n$ реальных экспериментов, при которых событие $A$ появилось $n_A$ раз.
    Отношение $\frac{n_A}{n}$ называется частотой события $A$.
    Эксперименты показывают, что при увеличении числа $n$ частота стабилизируется у некоторого числа,
    при котором мы понимаем статистическую вероятность: $P(A) \approx \frac{n_A}{n}$ при $n \to \infty$

    \hyperlink{classicdefinitionofprobability}{Классическое определение вероятности}: Пусть пространство случайных событий $\Omega$ содержит конечное число равновозможных исходов,
    тогда применимо классическое определение вероятности: \fbox{$P(A) = \frac{|A|}{|\Omega|} = \frac{m}{n}$}, где $n$ - число всех возможных исходов, $m$ - число благоприятных исходов

    \item Геометрическое определение вероятности. Задача Бюффона об игле.

    \hyperlink{geometricdefinitionofprobability}{Геометрическое определение вероятности}: Пусть $\Omega \subset \Real^n$ - замкнутая ограниченная область,
    $\mu(\Omega)$ - мера $\Omega$ в $\Real^n$ (например, длина отрезка, площадь области на плоскости, объем тела в пространстве), в этом случае применимо геометрическое определение вероятности: $P(A) = \frac{\mu(A)}{\mu(\Omega)}$

    \hyperlink{buffonsproblem}{Задача Бюффона об игле}: пусть пол вымощен ламинатом, $2l$ - ширина доски, на пол бросается игла длины, равной ширине доски,
    найти вероятность того, что игла пересечет стык доски

    Определим положение иглы координатами центра и углом, между иглой и стыком доски, причем можно считать, что эти величины независимы

    $\letsymbol x \in [0; l]$ - расстояние от центра до ближайшего края, $\varphi \in [0; \pi]$ - угол

    $\Omega = [0; l] \times [0; \pi]$

    Событие $A$ (пересечет стык) наступает, если $x \leq l \sin \varphi$

    $P(A) = \frac{S(A)}{S(\Omega)} = \frac{\int_0^\pi l \sin \varphi d \varphi}{\pi l} = \frac{2l}{\pi l} = \frac{2}{\pi}$

    \item Аксиоматическое определение вероятности. Вероятностное пространство. Свойства вероятности.

    \hyperlink{axiomaticdefinitionofprobability}{Аксиоматическое определение вероятности}: $\letsymbol\ \Omega$ - пространство элементарных исходов, $\mathcal{F}$ - его $\sigma$-алгебра событий.
    \textit{Вероятностью} на $(\Omega, \mathcal{F})$ называется функция $P: \mathcal{F} \to \Real$ со свойствами:

    \begin{enumerate}
        \item $P(A) \geq 0 \quad \forall A \in \mathcal{F}$ (неотрицательность)

        \item Если $A_1, A_2, \dots, A_n, \dots \in \mathcal{F}$ - несовместное, то $P(\sum_{i = 1}^\infty A_i) = \sum_{i = 1}^\infty P(A_i)$ (свойство счетной аддитивности)

        \item $P(\Omega) = 1$ (условие нормированности)
    \end{enumerate}

    \hyperlink{probabilityspace}{Вероятностное пространство}: Вероятностное пространство - тройка $(\Omega, \mathcal{F}, P)$

    \hyperlink{probabilityproperties}{Свойства вероятности}: 

    \begin{enumerate}
        \item Так как $\emptyset$ и $\Omega$ - несовместные, то $1 = P(\Omega) = P(\Omega + \emptyset) = 1 + P(\emptyset) \Longrightarrow P(\emptyset) = 0$

        \item Формула обратной вероятности: $P(A) = 1 - P(\overline{A})$

        \item $P(A) = 1 - P(\overline{A}) \leq 1$
    \end{enumerate}

    \item Аксиома непрерывности. Ее смысл и вывод.

    \hyperlink{continuityaxiom}{Аксиома непрерывности}: \Ths Пусть имеется убывающая цепочка событий $A_1 \supset A_2 \supset A_3 \supset \dots \supset A_n \supset \dots$ и $\bigcap_{i = 1}^\infty A_n = \emptyset$

    Тогда $P(A_n) \underset{n \to \infty}{\to} 0$

    При непрерывном изменении области $A \subset \Omega \subset \Real^n$ соответствующая вероятность $P(A)$ также должна изменятся непрерывно

    \begin{MyProof}
        Ясно, что $A_n = \sum_{i = n}^\infty A_i \overline{A}_{i + 1} + \prod_{i = n}^\infty A_i$

        $\prod_{i = n}^\infty A_i = A_n \cdot \prod_{i = n + 1}^\infty A_i = \prod_{i = 1}^n
        \cdot \prod_{i = n + 1}^\infty A_i = \prod_{i = 1}^\infty = \emptyset \Longrightarrow
        A_n = \sum_{i = n}^\infty A_n \overline{A_{n + 1}}$ и так как эти события несовместны,
        то по свойству счетной аддитивности $P(A_n) = \sum_{i = n}^\infty P(A_i \overline{A_{i + 1}})$ - это остаток (хвост) сходящегося ряда

        $P(A_1) = \sum_{i = 1}^\infty P(A_i \overline{A_{i + 1}}) = \sum_{i = 1}^{n - 1} P(A_i \overline{A_{i + 1}}) + P(A_n)$ и $P(A_n) \underset{n \to \infty}{\to} 0$ по необходимому признаку сходимости
    \end{MyProof}

    \item Свойства операций сложения и умножения. Формула сложения вероятностей.

    \hyperlink{probabilityoperationsproperties}{Свойства операций сложения и умножения}:

    \begin{enumerate}
        \item Свойство дистрибутивности: $A \cdot (B + C) = AB + AC$

        \item Формула сложения: если $A$ и $B$ несовместны, то $P(A + B) = P(A) + P(B)$

        \item Формула сложения вероятностей: $P(A + B) = P(A) + P(B) - P(AB)$
    \end{enumerate}

    \item Независимость событий. Независимые события в совокупности и попарно. Пример Бернштейна. 

    \hyperlink{independantevents}{Независимые события}: События $A$ и $B$ называются независимыми, если $P(A \cdot B) = P(A) \cdot P(B)$

    События $A_1, A_2, \dots A_n$ - независимы в совокупности, если для любого набора $i_1, i_2, \dots, i_k \ (2 \leq k \leq n)$
    $P(A_{i_1} \cdot A_{i_2} \cdot \dots \cdot A_{i_k}) = P(A_{i_1}) \cdot P(A_{i_2}) \cdot \dots \cdot P(A_{i_k})$

    \hyperlink{bernshteinsexample}{Пример Бернштейна}: Пусть имеется правильный тетраэдр, одна грань окрашена в красный, вторая в синий, третья в зеленый, а четвертая во все эти три цвета.

    Подбросили тетраэдр, $\letsymbol A$ - грань, которая содержит красный цвет, $B$ - синий, $C$ - зеленый.

    $P(A) = P(B) = P(C) = \frac{2}{4} = \frac{1}{2}$

    Так как $P(AB) = P(AC) = P(BC) = \frac{1}{4}$

    $P(AB) = \frac{1}{4} = \frac{1}{2} \cdot \frac{1}{2} = P(A) P(B)$ - попарная независимость

    $P(ABC) = \frac{1}{4} \neq P(A) P(B) P(C)$ - но вот независимость в совокупности не соблюдается

    \item Условная вероятность. Формула умножения событий.

    \hyperlink{conditionalprobability}{Условная вероятность} $P(A|B)$ (или $P_B(A)$) - вероятность события $A$, вычисленная в предположении, что событие $B$ уже произошло. $P(A|B) = \frac{P(AB)}{P(B)}$

    \hyperlink{eventsmultiplicationformula}{Формула умножения событий}:

    Для двух событий: $P(AB) = P(B) \cdot P(A|B) = P(A) \cdot P(B|A)$

    В общем случае: $P(A_1 A_2 A_3 \dots A_n) = P(A_1) P(A_2 | A_1) P(P_3 | A_1 A_2) \dots P(A_n | A_1 A_2 \dots A_{n - 1})$

    \item Полная группа событий. Формула полной вероятности. Формула Байеса.

    \hyperlink{completegroupofevents}{Полная группа событий}: События $H_1, H_2, \dots, H_n, \dots$ образуют полную группу событий, если они попарно несовместны и содержат все возможные элементарные исходы

    \hyperlink{formulaofcompleteprobability}{Формула полной вероятности}: $\letsymbol H_1, H_2, \dots, H_n, \dots$ - полная группа событий. Тогда $P(A) = \sum_{i = 1}^\infty P(H_i) P(A | H_i)$
    
    \hyperlink{bayesformula}{Формула Байеса}: $\letsymbol H_1, H_2, \dots, H_n$ - полная группа событий, и известно, что событие $A$ уже произошло

    Тогда $P(H_k | A) = \frac{P(H_k) P(A | H_k)}{\sum_{i = 1}^\infty P(H_i) P(A | H_i)}$

    \item Последовательность независимых испытаний. Формула Бернулли. Наиболее вероятное число успехов в схеме Бернулли.

    \hyperlink{bernoullischema}{Схемой Бернулли} называется серия одинаковых независимых экспериментов, каждый из которых имеет 2 исхода: произошло интересующее нас событие или нет

    \hyperlink{bernoulliformula}{Формула Бернулли}: Вероятность того, что при $n$ испытаниях произойдет ровно $k$ успехов, равна
    $p_n(k) = C_n^k p^k q^{n - k}$

    \hyperlink{themostprobablenumberofsuccesses}{Наиболее вероятное число успехов}: 

    \begin{enumerate}
        \item $np$ - целое, тогда $np + p$ - нецелое, и $k = np$ - наиболее вероятное

        \item $np + p$ - нецелое, тогда $k = \lfloor np + p \rfloor$

        \item $np + p$ - целое, тогда $np + p - 1$ - целое, тогда $k \in \{np + p - 1, np + p\}$
    \end{enumerate}

    \item Локальная и интегральная формулы Муавра-Лапласа (без док-ва).

    \hyperlink{localformulademoivrelaplace}{Локальная формула}: $p_n(k) \underset{n \to \infty}{\longrightarrow} \frac{1}{\sqrt{npq}} \varphi(x)$, где $\varphi(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}$ - функция Гаусса, 
    $x = \frac{k - np}{\sqrt{npq}}$

    \hyperlink{integralformulademoivrelaplace}{Интегральная формула}: $p_n(k_1 \leq k \leq k_2) \underset{n \to \infty}{\longrightarrow} \Phi(x_2) - \Phi(x_1)$, где $\Phi(x) = \frac{1}{\sqrt{2\pi}} \int_0^x e^{-\frac{z^2}{2}} dz$ - функция Лапласа,
    $x_1 = \frac{k_1 - np}{\sqrt{npq}}$ - отклонение от левой границы, $x_2 = \frac{k_2 - np}{\sqrt{npq}}$ - отклонение от правой

    \item Вероятность отклонения относительной частоты от вероятности события. Закон больших чисел Бернулли.

    \hyperlink{probabilityofdeviation}{Вероятность отклонения относительной частоты} от вероятности события

    $n$ - число испытаний, $p = p(A), \frac{n_A}{n}$ - экспериментальная частота

    $p\left(|\frac{n_A}{n} - p| \leq \varepsilon\right) = p\left(-\varepsilon \leq \frac{n_A}{n} - p \leq \varepsilon\right) \underset{n \to \infty}{\longrightarrow} 2\Phi\left(\frac{\sqrt{n}\varepsilon}{\sqrt{pq}}\right)$

    \hyperlink{lawofbignumbersbernoulli}{Закон больших чисел Бернулли}: $p\left(|\frac{n_A}{n} - p| \leq \varepsilon\right) \underset{n \to \infty}{\longrightarrow} 2 \Phi\left(\frac{\varepsilon}{\sqrt{pq}}\sqrt{n}\right) \to 1$ - 
    закон больших чисел показывает, что вероятность попадания относительной частоты в $\varepsilon$-трубу приближается к 1

    \item Схемы испытаний: Бернулли, до первого успеха. Биномиальное и геометрическое распределения. Свойство отсутствия последействия.

    \hyperlink{bernoullischema2}{Схема Бернулли}: $\letsymbol v_n$ - число успехов в серии из $n$ испытаний; 
    $P_n(v_n = k) = C^k_n p^k q^{n - k}, \quad\quad k = 0, 1, \dots, n$

    \hyperlink{binomialdistribution}{Биномиальное распределение}: Соответствие $k \rightarrow C^k_n p^k q^{n - k}, \quad k = 0, \dots, n$ называется биномиальным распределением
    (обозначается $B_{n,p}$ или $B(n, p)$)

    \hyperlink{untilfirstsuccessschema}{Схема до первого успеха}: Пусть проводится бесконечная серия испытаний, которая заканчивается после первого успешного испытания
    под номером $\tau$, тогда вероятность $P(\tau = k) = q^{k - 1} p, \quad\quad k = 1, 2, \dots$

    \hyperlink{geometricdistribution}{Геометрическое распределение}: Соответствие $k \rightarrow q^{k - 1} p, k \in \Natural$ называется геометрическим
    распределение вероятности (обозначается $G_p$ или $G(p)$)

    Геометрическое распределение обладает свойством \enqoute{нестарения} или свойством отсутствия
    последействия: \Ths $\letsymbol P(\tau = k) = q^{k - 1} p, k \in \Natural$. Тогда $\forall n, k \geq 0 \quad P(\tau > n + k \ | \ \tau > n) = P(\tau > k)$

    \item Урновая схема с возвратом и без возврата. Гипергеометрическое распределение. Теорема об его асимптотическом приближении к биномиальному.

    \hyperlink{urnschema}{Урновая схема}: В урне $N$ шаров, из которых $K$ шаров белые, $N - K$ - черные.
    Из урны вынимаем (без учета порядка) $n$ шаров. Найти вероятность, что из них $k$ белых

    а) Схема с возвратом (после каждого раза кладем шар обратно). В этом случае вероятность вынуть белый шар одинакова и
    равна $\frac{K}{N}$. Получаем схему Бернулли: $P_n(k) = C^k_n \left(\frac{K}{N}\right)^k \left(1 - \frac{K}{N}\right)^{n - k}$

    б) Схема без возврата - вынутый шар мы выбрасываем, тогда
    $P_{N, K} (n, k) = \frac{C^k_K C^{n - k}_{N - K}}{C^n_N}$

    \hyperlink{hypergeometricdistribution}{Гипергеометрическое распределение}: Соответствие $k \rightarrow \frac{C^k_K C^{n - k}_{N - K}}{C^n_N}, k = 0, \dots, n$ называется гипергеометрическим
    распределением

    \hyperlink{hypergeometricasimptotic}{Теорема о приближении к биномиальному}: \Ths Если $K, N \to \infty$ таким образом, что $\frac{K}{N} \to p \in (0;1)$, а $n$ и $0 \leq k \leq n$ фиксированы, то
    вероятность при гипергеометрическом распределении будет стремиться к биномиальному:
    $P_{N,K} (n, k) = \frac{C^k_K C^{n - k}_{N - K}}{C^n_N} \rightarrow C^k_n \left(\frac{K}{N}\right)^k \left(1 - \frac{K}{N}\right)^{n - k}$

    \item Схема Пуассона. Формула Пуассона. Оценка погрешности в формуле Пуассона.
    
    \hyperlink{poissonschema}{Схема Пуассона}: вероятность числа успеха при одном испытании $p_n$ зависит от числа испытаний $n$, причем таким образом, что $n p_n \approx \lambda = const$, 
    $\lambda$ - интенсивность появления редких событий в единицу времени в потоке испытаний. Применимо при $p$ близком к 0 или к 1.

    \hyperlink{poissonformula}{Формула Пуассона}: \Ths Пусть $n \to \infty, p_n \to 0$ таким образом, что $n p_n \to \lambda = const > 0$.
    Тогда вероятность $k$ успехов при $n$ испытаниях: $P_n(k) = C^k_n p_n^k (1 - p_n)^{n - k} \underset{n \to \infty}{\rightarrow} = \frac{\lambda^k}{k!} e^{-\lambda}$

    \hyperlink{errorinpoissonformula}{Оценка погрешности}: \Ths Пусть $v_n$ - число успехов при $n$ испытаниях в схеме Бернулли

    $p$ - вероятность успеха при одном испытании, $\lambda = np$, $A \subset \{0, 1, \dots, n\}$ - произвольное подмножество чисел

    Тогда $|P_n (v_n \in A) - \sum_{k \in A} \frac{\lambda^k}{k!} e^{-\lambda}| \leq \min (p, np^2) = \min (p, p\lambda)$

    \item Случайные величины, определение. Измеримость функции, ее смысл. Вероятностное пространство $(\Real, B, P)$. Распределение случайной величины.

    \hyperlink{randomvaluedefinition}{Случайной величиной}, заданной на вероятностном пространстве $(\Omega, \mathcal{F}, p)$, называется
    $\mathcal{F}$-измеримая функция $\xi \ : \Omega \to \Real$, которая сопоставляет каждому элементарному исходу \
    некоторое вещественное число

    \hyperlink{measurabilityoffunction}{Измеримость}: На вероятностном пространстве $(\Omega, \mathcal{F}, p)$ функция $\xi \ : \ \Omega \to \Real$ называется
    $\mathcal{F}$-измеримой, если $\forall x \in \Real \ \{\omega \in \Omega \ | \ \xi(\omega) < x\} \in \mathcal{F}$
    (то есть $\xi^{-1}(y) \in \mathcal{F}$, где $y \in (-\infty; x)$)

    Смысл измеримости: если задана случайная величина $\xi$, то мы можем задать вероятность попадания случайной
    величины в интервал $(-\infty; x)$: $p(\xi \in (-\infty; x)) = p(\{\omega \in \Omega \ | \ \xi(\omega) < x\})$

    \hyperlink{probabilityspacerbp}{Вероятностное пространство $(\Real, B, P)$}: Пусть $\xi$ задана на вероятностном пространстве $(\Omega, \mathcal{F}, p)$, с помощью нее получаем новой вероятностное
    пространство $(\Real, \mathcal{B}(\Real), p_\xi)$, с которым проще работать

    \hyperlink{randomvaluedistribution}{Распределение случайной величины}: Функция $p(B), B \in \mathcal{B}(\Real)$, ставящая в соответствие каждому Борелевскому множеству вероятность,
    называется распределением случайной величины $\xi$

    \item Дискретные случайные величины. Определение, закон распределения, числовые характеристики.

    \hyperlink{discreterandomvalue}{Дискретная случайная величина}: Случайная величина $\xi$ имеет дискретное рапределение, если она принимает не более, чем счетное число значений.
    То есть существует конечный или счетный набор чисел $\{x_1, x_2, \dots, x_n, \dots\}$ такой, что $p(\xi = x_i) = p_i > 0$ и $\sum_{i = 0}^\infty p_i = 1$

    Таким образом, дискретная случайная величина (ДСВ) задается законом распределения:

    \begin{tabular}{c|c|c|c|c|cl}
        $\xi$ & $x_1$ & $x_1$ & \dots & $x_n$ & \dots & \text{\qquad   - значения случайной величины} \\
        \cline{1-6}
        $p$   & $p_1$ & $p_1$ & \dots & $p_n$ & \dots & \text{\qquad   - вероятности этих значений}
    \end{tabular}

    \hyperlink{attributesofdiscreterandomvalue}{Характеристики дискретной случайной величины}: 

    Математическим ожиданием $E\xi$ случайной величины $\xi$ называется число
    $E\xi = \sum_{i = 1}^\infty x_i p_i$

    Дисперсией $D\xi$ случайной величины $\xi$ называют среднее квадратов ее отклонения от математического ожидания:
    $D\xi = E (\xi - E\xi)^2$ или $D\xi = \sum_{i = 0}^\infty (x_i - E\xi)^2 p_i$ при условии, что данный ряд сходится

    Дисперсию обычно удобно считать по формуле $D\xi = E\xi^2 - (E\xi)^2 = \sum_{i = 1}^n x^2_i p_i - E\xi^2$

    Средним квадратическим отклонением (СКО) $\sigma_\xi$ называется величина $\sigma_\xi = \sqrt{D\xi}$

    $m_k = E\xi^k$ - момент $k$-ого порядка случайной величины $\xi$ (также называют начальным моментом)

    $\mu_k = E(\xi - E\xi)^k$ - центральный момент $k$-ого порядка

    \item Свойства математического ожидания и дисперсии дискретной случайной величины.

    \hyperlink{expectedvalueandvarianceproperties}{Свойства}: 

    \ThNs{1} Случайная величина $\xi$ имеет вырожденное распределение, если $\xi(\omega) = \mathrm{const} \ \ \forall \omega \in \Omega$

    \begin{tabular}{c|c}
        $\xi$ & $C$ \\
        \hline
        $p$   & $1$
    \end{tabular}

    $E\xi = C \qquad D\xi = 0$

    \ThNs{2} Свойство сдвига: $E(\xi + C) = E\xi + C; D (\xi + C) = D\xi$

    \ThNs{3} Свойство растяжения: $E(C\xi) = CE\xi$, $D(C\xi) = C^2 D\xi$

    \ThNs{4} $E(\xi + \eta) = E\xi + E\eta$ (из третьего свойства матожидание - линейная функция)

    \Def Дискретные случайные величины $\xi$ и $\eta$ независимы, если $p(\xi = x_i, \eta = y_i) = p(\xi = x_i) \cdot p(\eta = y_i) \ \forall i, j$.
    То есть случайные величины принимают свои величины независимо друг от друга

    \ThNs{5} Если случайные величины $\xi$ и $\eta$ независимы, то $E(\xi \eta) = E\xi \cdot E\eta$; обратное неверно

    \ThNs{6} $D\xi = E\xi^2 - (E\xi)^2$

    \Def $D(\xi + \eta) = D\xi + D\eta + 2\mathrm{cov} (\xi, \eta)$,
    где $\mathrm{cov}(\xi, \eta) = E(\xi\eta) - E\xi E\eta$ - ковариация случайных величин (равна 0 при независимых величинах) - индикатор наличия связи между случайными величинами

    \ThNs{7} Если случайные величины $\xi$ и $\eta$ независимы, то $D(\xi + \eta) = D\xi + D\eta$

    \ThNs{8} Общая формула дисперсии суммы: $D(\xi_1 + \xi_2 + \dots + \xi_n) = \sum_{i = 1}^n D \xi_i + 2\sum_{i, j (i \neq j)} \mathrm{cov} (\xi_i, \xi_j)$

    \item Стандартные дискретные распределения и их числовые характеристики (Бернулли, биномиальное, геометрическое, Пуассона).
    
    \hyperlink{bernoullidistribution}{Распределение Бернулли}: $B_p$ (с параметром $0 < p < 1$), $\xi$ - число успехов при одном испытании, $p$ - вероятность успеха при одном испытании

    \begin{tabular}{c|c|c}
        $\xi$ & $0$        & $1$    \\
        \hline
        $p$   & $1 - P(A)$ & $P(A)$
    \end{tabular}

    Матожидание: $E\xi = p$

    Дисперсия: $D\xi = p(1 - p) = pq$

    \hyperlink{binomialdistributionproperties}{Биномиальное распределение} $B_{n,p}$ (с параметрами $n, p$),
    $\xi$ - число успехов в серии из $n$ испытаний, $p$ - вероятность успеха при одном испытании

    $p(\xi = k) = C^k_n p^k q^{n - k}, \ k = 0, 1, \dots, n \Longleftrightarrow \xi \in B_{n,p}$

    $E\xi_i = p; \quad D\xi_i = pq$

    $E\xi = E\xi_1 + \dots + E\xi_n = p + \dots + p = np$

    $D\xi = D\xi_1 + \dots + D\xi_n = pq + \dots + pq = npq$

    \hyperlink{geometricdistributionproperties}{Геометрическое распределение} $G_p$ (с параметром $p$),
    $\xi$ - номер 1-ого успешного испытания в бесконечной серии

    $p(\xi = k) = q^{k - 1}p, \ k = 1, 2, 3, \dots \Longleftrightarrow \xi \in G_p$

    $E\xi = \frac{1}{p}, D\xi  = \frac{q}{p^2}$

    \hyperlink{poissondistribution}{Распределение Пуассона} $\Pi_\lambda$ (с параметром $\lambda > 0$)

    Случайная величина $\xi$ имеет распределение Пуассона с параметром $\lambda > 0$, если $p(\xi = k) = \frac{\lambda^k}{k!}e^{-\lambda}, \ k = 0, 1, 2, \dots$

    $E\xi = \lambda = np, D\xi = \lambda$


    \item Функция распределения и ее свойства (в свойствах 4, 5, 6 достаточно привести одно из доказательств).
    
    \hyperlink{distributionfunction}{Функция распределения} $F_\xi(x)$ случайной величины $\xi$ называется функция $F_\xi(x) = P(\xi < x)$

    \hyperlink{distributionfunctionproperties}{Свойства}: 

    1) $F(x)$ ограничена $0 \leq F(x) \leq 1$

    2) $F(x)$ неубывающая функция: $x_1 < x_2 \Longrightarrow F(x_1) \leq F(x_2)$ 

    3) $p(\alpha \leq \xi < \beta) = F(\beta) - F(\alpha)$

    4) $\lim_{x \to -\infty} F(x) = 0; \quad \lim_{x \to +\infty} F(x) = 1$
    
    5) $F(x)$ непрерывна слева: $F(x_0 - 0) = F(x_0)$

    6) Скачок в точке $x_0$ равен вероятности попадания в данную точку: $F(x_0 + 0) - F(x_0) = p(\xi = x_0)$ или $F(x_0 + 0) = p(\xi = x_0) + p(\xi < x_0) = p(\xi \leq x_0)$

    7) Если функция распределения непрерывна в точке $x = x_0$, то очевидно, что вероятность попадания в эту точка $p(\xi = x_0) = 0$ (следствие из 6 пункта)
    
    8) Если $F(x)$ непрерывна $\forall x \in \Real$, то $p(\alpha \leq \xi < \beta) = p(\alpha < \xi < \beta) = p(\alpha \leq \xi \leq \beta) = p(\alpha < \xi \leq \beta) = F(\beta) - F(\alpha)$
    
    \item Абсолютно непрерывные случайные величины. Плотность и ее свойства.

    \hyperlink{continuousdistributionproperties}{Абсолютно непрерывне случайные величины}: Случайная величина $\xi$ имеет абсолютно непрерывное распределение, если существует $f_\xi(x)$ такая, что $\forall B \in \mathcal{B}(\Real)
    \ p(\xi \in B) = \int_B f_\xi(x)dx$

    \hyperlink{densityfunctiondefinition}{Функция плотности}: Функция $f_\xi$ называется плотностью распределения случайной величины

    \hyperlink{densityfunctionproperties}{Свойства}:

    1) Вероятносто-геометрический смысл плотности: $p(\alpha \leq \xi < \beta) = \int_{\alpha}^\beta f_\xi(x) dx$

    2) Условие нормировки: $\int_{-\infty}^{+\infty} f_\xi(x)dx = 1$

    3) $F_\xi(x) = \int_B f_\xi(x)dx$

    4) $F_\xi(x)$ непрерывна 

    5) $F_\xi(x)$ дифференцируема почти везде и $f_\xi(x) = F^\prime_\xi(x)$ для почти всех $x$

    6) $f_\xi(x) \geq 0$ по определению и как производная неубывающей $F_\xi(x)$

    7) $p(\xi = x) = 0 \ \forall x \in \Real$ - так как $F_\xi(x)$ непрерывна

    8) $p(\alpha \leq \xi < \beta) = p(\alpha < \xi < \beta) = p(\alpha \leq \xi \leq \beta) = p(\alpha < \xi \leq \beta) = F(\beta) - F(\alpha)$

    9) \Ths Если $f(x) \leq 0$ и $\int_{-\infty}^{\infty} f(x)dx$ (выполнены свойства 2 и 6), то $f(x)$ - плотность некоторого распределения

    \item Числовые характеристики абсолютно непрерывной случайной величины, их свойства.

    \hyperlink{attributesofcontinuousrandomvariable}{Характеристики}:

    Математическим ожиданием $E\xi$ случайной абсолютно непрерывной величины $\xi$ называется величина $E\xi = \int_{-\infty}^{\infty} xf_\xi(x) dx$ 
    при условии, что данный интеграл сходится абсолютно, то есть $\int_{-\infty}^\infty |x|f_\xi(x)dx < \infty$

    Дисперсией $D\xi$ случайной величины $\xi$ называется величина $D\xi = E(\xi - E\xi)^2 = \int_{-\infty}^\infty (x - E\xi)^2 f_\xi(x) dx$ при условии,
    что данный интеграл сходится. Вычислять удобно по формуле $D\xi = E\xi^2 - (E\xi)^2 = \int_{-\infty}^\infty x^2 f_\xi(x)dx - (E\xi)^2$

    Среднее квадратическое отклонение $\sigma_\xi = \sqrt{D\xi}$ определяется, как корень дисперсии

    $m_k = E\xi^k = \int_{-\infty}^\infty x^k f_\xi(x)dx$ - момент $k$-ого порядка

    $\mu_k = E(\xi - E\xi)^k = \int_{-\infty}^\infty (x - E\xi)^k f_\xi(x)dx$ - центральный момент $k$-ого порядка
    
    Медианой $Me$ абсолютно непрерывной случайной величины $\xi$ называется значение случайной величины $\xi$, такое что $p(\xi < Me) = p(\xi > Me) = \frac{1}{2}$
    
    Модой $Mo$ случайной величины $\xi$ называется точка локального максимума плотности

    \item Равномерное распределение. 

    \hyperlink{uniformdistribution}{Равномерное распределение}: Случайная величина $\xi$ имеет равномерное распределение $\xi \in U(a, b)$, если ее плотность
    на этом отрезке постоянна. Получаем функцию плотности $f_\xi(x) = \begin{cases}0, \quad x < a \\ \frac{1}{b - a}, \quad a \leq x < b \\ 0 \quad x \geq b\end{cases}$ \hfill {\scriptsize $\frac{1}{b - a}$ из усл. нормировки}

    $F(x) = \int_{-\infty}^\infty f(x)dx = \begin{cases}0, \quad x < a \\ \frac{x - a}{b - a}, \quad a \leq x < b \\ 1 \quad x \geq b\end{cases}$

    $E\xi = \frac{a + b}{2}, \quad D\xi = \frac{(b - a)^2}{12}, \quad \sigma = \frac{b - a}{2\sqrt{3}}$

    $p(\alpha < \xi < \beta) = \frac{\beta - \alpha}{b - a}$ при условии, что $\alpha, \beta \in [a, b]$

    \item Показательное распределение. Свойство нестарения.

    \hyperlink{exponentialdistribution}{Показательное распределение}: Случайная величина $\xi$ имеет показательное (или экспоненциальное) распределение с параметром $\alpha > 0$ (обозн. $\xi \in E_\alpha$),
    если ее плотность имеет вид: $f_\xi(x) = \begin{cases}0, \quad x < 0 \\ \alpha e^{-\alpha x}, \quad x \geq 0\end{cases}$

    $F_\xi(x) = \begin{cases}0, \quad x < 0 \\ \int_0^x \alpha e^{-\alpha x} = 1 - e^{-\alpha x}, \quad x \geq 0\end{cases}$

    $E\xi = \frac{1}{\alpha}, \quad D\xi = \frac{1}{\alpha^2}, \quad \sigma = \frac{1}{\alpha}$

    $p(\alpha < \xi < \beta) = F(b) - F(a) = e^{-a\alpha} - e^{-b\alpha} \quad\quad\quad a, b \geq 0$

    Из непрерывных случайных величин только показательная обладает свойством нестарения:
    \Ths $\letsymbol \xi \in E_\alpha$. Тогда $p(\xi < x + y \ | \ \xi > x) = p(\xi > y) \quad\quad \forall x, y > 0$

    \item Нормальное распределение. Стандартное нормальное распределение, его числовые характеристики.

    \hyperlink{normaldistribution}{Нормальное распределение}: Случайная величина $\xi$ имеет нормальное распределение с параметрами $a$ и $\sigma^2$ (обозн. $\xi \in N(a, \sigma^2)$), если
    ее плотность имеет вид: $f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - a)^2}{2\sigma^2}}$

    $F(x) = \frac{1}{\sigma \sqrt{2\pi}} \int_{-\infty}^x e^{-\frac{(t - a)^2}{2\sigma^2}} dt$

    $E\xi = a, \quad D\xi = \sigma^2, \quad \sigma = \sigma$

    \hyperlink{standardnormaldistribution}{Стандартным нормальным распределением} называется нормальное распределение с параметрами $a = 0, \sigma^2 = 1$: $\xi \in N(0, 1)$

    Плотность: $\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}$ - функция Гаусса

    Распределение: $F_0(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{-\frac{z^2}{2}} dz$ - функция стандартного нормального распределения

    $E\xi = 0; \ D\xi = 1$

    \item Связь между стандартным нормальным и нормальным распределениями. Следствия.

    \hyperlink{connectionbetweennormalandstandard}{Связь}: 

    1) $\letsymbol \xi \in N(a, \sigma^2)$. Тогда $F_\xi(x) = F_0\left(\frac{x - a}{\sigma}\right)$

    2) Если $\xi \in N(a, \sigma^2)$, то $\eta = \frac{\xi - a}{\sigma} \in N(0, 1)$ (процесс $\xi \to \eta$ называется стандартизацией)

    3) $\letsymbol \xi \in N(a, \sigma^2)$. Тогда $p(\alpha < \xi < \beta) = \Phi\left(\frac{\beta - a}{\sigma}\right) - \Phi\left(\frac{\alpha - a}{\sigma}\right)$

    4) Вероятность попадания в симметричный интервал (вероятность отклонения случайной величины от матожидания) 
    $p(|\xi - a| < t) = 2\Phi\left(\frac{t}{\sigma}\right)$

    5) Правило 3 \enquote{сигм}: $p(|\xi - a| < 3\sigma) \approx 0.9973$ - попадание случайной величины нормального распределения в интервал $(a - 3\sigma, a + 3\sigma)$ близко к 1

    6) Свойство линейности: если случайная величина $\xi \in N(a, \sigma^2)$, то $\eta = \gamma \xi + b \in N(a \gamma + b, \gamma^2 \sigma^2)$ 
    
    7) Устойчивость относительно суммирования: если случайные величины $\xi_1 \in N(a_1, \sigma_1^2), \xi_2 \in N(a_2, \sigma_2^2)$, и они независимы, то $\xi_1 + \xi_2 \in N(a_1 + a_2, \sigma^2_1 + \sigma^2_2)$

    
    \item Сингулярные распределения. Теорема Лебега (без док-ва).

    \hyperlink{singulardistribution}{Сингулярное распределение}: Случайная величина $\xi$ имеет сингулярное распределение, если $\exists B$ - Борелевское множество с нулевой мерой Лебега $\lambda(B) = 0$, такое что $p(\xi \in B) \in 1$, но $P(\xi = x) = 0 \ \, \forall x \in B$

    \hyperlink{lebesguetheorem}{Теорема Лебега}: \ThNs{Лебега}

    $\letsymbol F_\xi(x)$ - функция распределения $\xi$. Тогда $F_\xi(x) = p_1 F_1(x) + p_2 F_2(x) + p_3 F_3(x)$, где $p_1 + p_2 + p_3 = 1$

    $F_1$ - функция дискретного распределения

    $F_2$ - функция абсолютно непрерывного распределения

    $F_3$ - функция сингулярного распределения

    То есть существуют только дискретное, абсолютно непрерывное, сингулярное распределения и их смеси

    \item Преобразования случайных величин. Стандартизация случайной величины. 

    \hyperlink{standardizationofrandomvalue}{Стандартизация}: Пусть имеется случайная величина $\xi$. Соответствующей ей стандартной величиной называется
    случайная величина $\eta = \frac{\xi - E\xi}{\sigma}$

    $E\eta = 0; D\eta = 1$

    \hyperlink{randomvaluetransformation}{Преобразование}: Если $\xi$ - дискретная случайная величина, то ее законы распределения находятся просто: значения $x_i$ в верхней строке заменяем $g(x_i)$, вероятности остаются прежние.
    
    \item Теорема о монотонном преобразовании. Линейное преобразование случайной величины. (без док-ва).
    
    \hyperlink{monotonoustransformationtheorem}{Теорема о монотонном преобразовании}: \Ths Пусть $f_\xi(x)$ - плотность случайной величины $\xi$, $g(x)$ - строго монотонная функция. Тогда 
    случайная величина $\eta = g(\xi)$ имеет плотность $f_\eta(x) = |h^\prime(x)| f_\xi(h(x)), \qquad\qquad \text{где } h(g(x)) = x$

    Если $g(x)$ не является монотонной функцией, то поступаем следующим образом: разбиваем $g(x)$ на интервалы монотонности, 
    для каждого $i$-ого интервала находим $h_i(x)$ и плотность случайной величины ищем по \textit{формуле Смирнова}: 
    $f_\eta(x) = \sum_{i = 0}^n |h_i^\prime(x)| f_\xi(h_i(x))$
    
    \hyperlink{lineartransformation}{Линейное преобразование}: \Ths Пусть $\xi$ имеет плотность $f_\xi(x)$, тогда $\eta = a\xi + b$, где $a \neq 0$, имеет плотность $f_\eta(x) = \frac{1}{|a|}f_\xi\left(\frac{x - b}{a}\right)$
    
    \item Квантильное преобразование. Моделирование случайной величины с помощью датчика случайных чисел.

    \hyperlink{quantiletransformation}{Квантильное преобразование}: Пусть функция распределения случайной величины $\xi$ $F_\xi(x)$ - непрерывная функция. 
    Тогда $\eta = F(\xi) \in U(0, 1)$ - стандартное равномерное распределение

    Пусть $\eta \in U(0, 1)$ - стандартное равномерное распределение, $F(x)$ - произвольная функция распределения. 
    Тогда $\xi = F^{-1}(\eta)$ имеет функцию распределения $F(x)$

    Преобразование $\xi = F^{-1}(\eta)$ называют квантильным

    Смысл: датчики случайных чисел имеют стандартное равномерное распределение, из теоремы следует, что при помощи
    датчика случайных чисел и квантильного преобразования мы сможем смоделировать любое нужно распределение


    \item Виды сходимостей случайных величин, связь между ними. Теорема об эквивалентности сходимостей к константе (все без док-ва).

    \hyperlink{convergencetypes}{Виды сходимостей}:

    \begin{itemize}
        \item Сходимость \enquote{почти наверное}

        \Defs Последовательность случайных величин $\{\xi_n\}$ сходится \enquote{почти наверное} к случайной величине $\xi$ при $n \to \infty$ ($\xi_n \overset{\text{п. н.}}{\longrightarrow} \xi$), 
        если $p(\omega \in \Omega \ | \ \xi_n(\omega) \underset{n \to \infty}{\longrightarrow} \xi(\omega)) = 1$

        \item Сходимость по вероятности

        \Defs Последовательность случайных величин $\{\xi_n\}$ сходится по вероятности к случайной величине $\xi$ при $n \to \infty$
        ($\xi_n \overset{p}{\longrightarrow} \xi$), если $\forall \varepsilon > 0 \quad p(|\xi_n - \xi| < \varepsilon) \underset{n \to \infty}{\longrightarrow} 1$
        
        \item Слабая сходимость

        \Defs Последовательность случайных величин $\xi_n$ слабо сходится к случайной величине $\xi$ при $n \to \infty$
        ($\xi_n \rightrightarrows \xi$), если $F_{\xi_n}(x) \longrightarrow F_\xi(x) \forall x$, где $F_\xi(x)$ - непрерывна
    \end{itemize}

    \hyperlink{connectionbetweenconvergencetypes}{Связь}: 

    \Ths $\xi_n \overset{\text{п. н.}}{\longrightarrow} \xi \Longrightarrow \xi_n \overset{p}{\longrightarrow} \xi \Longrightarrow \xi_n \rightrightarrows \xi$

    \Ths Если $\xi_n \rightrightarrows C = \mathrm{const}$, то $\xi_n \overset{p}{\longrightarrow} C$

    \Nota В общем случае не только из слабой сходимости не следует сходимость по вероятности, но и бессмысленно говорить
    об этом, так как слабая сходимость - это сходимость не случайных величин, а их распределений

    \item Математическое ожидание преобразованной случайной величины. Свойства моментов.
    
    \hyperlink{expectedvalueoftransformedvariable}{Матожидание}: \Ths Если $\xi$ - дискретная случайная величина, то $Eg(\xi) = \sum_{i = 1}^\infty g(x_i) \cdot p(\xi = x_i)$

    Для непрерывной случайной величины $Eg(\xi) = \int_{-\infty}^{\infty} g(x) f_\xi(x) dx$

    \hyperlink{momentsproperties}{Свойства моментов}: 1) Если $\xi \geq 0$, то $E\xi \geq 0$

    2) Если $\xi \leq \eta$, то $E\xi \leq E\eta$

    3) Если $|\xi| \leq |\eta|$, то $E|\xi|^k \leq E|\eta|^k$

    4) Если существует момент $m_t$ случайной величины $\xi$, то существует $m_s$ при $s < t$ (при условии, что интеграл/сумма сходятся)

    
    \item Неравенство Йенсена, следствие.

    \hyperlink{jensensinequality}{Неравенство Йенсена}: \Ths Пусть функция $g(x)$ выпукла вниз, тогда для любой случайной величины $\xi$ $Eg(\xi) \geq g(E\xi)$

    \Nota Если $g(x)$ выпукла вверх, знак неравенства меняется

    Следствие: $Ee^\xi \geq e^{E\xi}, \quad E\xi^2 \geq (E\xi)^2, \quad E|\xi| \geq |E\xi|, \quad E\ln(\xi) \leq \ln(E\xi), \quad E\frac{1}{\xi} \geq \frac{1}{E\xi}$ при $\xi > 0$

    \item Неравенства Маркова, Чебышева, правило трех сигм.

    Для $\xi$, у которой существует матожидание, верно: 

    \hyperlink{markovsinequality}{Неравенство Маркова}: \Ths $p(|\xi| \geq \varepsilon) \leq \frac{E|\xi|}{\varepsilon} \quad \forall \varepsilon > 0$
    
    \hyperlink{chebyshevsinequality}{Неравенство Чебышева}: \Ths $P(|\xi - E\xi| \geq \varepsilon) \leq \frac{D\xi}{\varepsilon^2}$
    
    \hyperlink{ruleofthreesigmas}{Правило \enquote{трех сигм}}: \Ths $P(|\xi - E\xi| \geq 3\sigma) \leq \frac{1}{9}$

    \item Среднее арифметическое одинаковых независимых случайных величин. Закон больших чисел Чебышева.

    \hyperlink{averagevalueofrandomvariables}{Среднее арифметическое}: $\frac{S_n}{n} = \frac{\xi_1 + \dots + \xi_n}{n}$

    $E\left(\frac{S_n}{n}\right) = \frac{1}{n} (E\xi_1 + \dots + E\xi_n) = \frac{1}{n} na = a = E\xi_1$ - математическое ожидание не меняется

    $D\left(\frac{S_n}{n}\right) = \frac{1}{n^2} (D\xi_1 + \dots + D\xi_n) = \frac{1}{n^2} nd = \frac{d}{n} = \frac{D\xi_1}{n}$ - дисперсия уменьшилась в $n$ раз

    $\sigma\left(\frac{S_n}{n}\right) = \frac{\sigma}{\sqrt{n}}$ - СКО уменьшилось в $\sqrt{n}$ раз

    \hyperlink{lawofbignumberschebyshev}{Закон больших чисел Чебышев}: \Ths Пусть $\xi_1, \dots, \xi_n, \dots$ - последовательность независимых одинаково распределенных с конечным вторым моментом,
    тогда $\frac{\xi_1 + \dots + \xi_n}{n} \overset{p}{\underset{n \to \infty}{\longrightarrow}} E\xi_1$

    \item Вывод закона больших чисел Бернулли из закона больших чисел Чебышева. Законы больших чисел Хинчина и Колмогорова (только формулировки).

    \hyperlink{lawofbignumbersbernoulli2}{ЗБЧ Бернулли}: \Ths Пусть $v_n$ - число успехов из $n$ независимых испытаний, $p = P(A)$ - вероятность успеха при одном испытании.
    Тогда $\frac{v_n}{n} \overset{p}{\longrightarrow} P(A)$

    \begin{MyProof}
        $v_n = \xi_1 + \dots + \xi_n$, где $\xi_i \in B_p$ - число успехов при $i$-ом испытании

        $E\xi_i = p; D\xi_i = pq$

        $\frac{v_n}{n} \overset{p}{\longrightarrow} E\xi_1 = p$

        $p\left(\left|\frac{v_n}{n} - p\right| \geq \varepsilon\right) \leq \frac{D\xi_1}{n\varepsilon^2} = \frac{pq}{n\varepsilon^2}$
    \end{MyProof}

    \hyperlink{lawofbignumberskhinchin}{ЗБЧ Хинчина}: \Ths $v_n = \xi_1 + \dots + \xi_n$ последовательность независимых одинаково распределенных случайных величин с конечным первым моментом, тогда
    $\frac{\xi_1 + \dots + \xi_n}{n} \overset{p}{\longrightarrow} E\xi_i$

    \hyperlink{lawofbignumberskolmogorov}{ЗБЧ Колмогорова}: В условиях теоремы Хинчина $\frac{\xi_1 + \dots + \xi_n}{n} \overset{\text{п.н.}}{\longrightarrow} E\xi_1$

    \item Совместные распределения случайных величин. Функция совместного распределения, ее свойства. Независимость случайных величин.
    
    \hyperlink{jointdistribution}{Совместное распределение}: Случайным вектором $\vec{\xi} = (\xi_1, \xi_2, \dots, \xi_n)$ называется упорядоченный набор случайных величин, заданных
    на одном вероятностном пространстве

    Случайный вектор задает отображение $(\xi_1, \dots, \xi_n) (\omega) : \Omega \longrightarrow \Real^n$

    \hyperlink{jointdistributionfunction}{Функция совместного распределения}: Функцией совместного распределения случайных величин $\xi_1, \xi_2, \dots, \xi_n$ называется функция 
    $F_{\xi_1, \xi_2, \dots, \xi_n}(x_1, x_2, \dots, x_n) = P(\xi_1 < x_1, \xi_2 < x_2, \dots, \xi_n < x_n)$

    \hyperlink{jointdistributionfunctionproperties}{Свойства}: 

    \begin{enumerate}
        \item $0 \leq F_{\xi, \eta}(x, y) \leq 1$
        \item $F_{\xi, \eta}(x, y)$ - неубывающая по каждому аргументу
        \item $\lim_{x \to -\infty} F_{\xi, \eta}(x, y) = \lim_{y \to -\infty} F_{\xi, \eta}(x, y) = 0, $
        $\lim_{\substack{x \to \infty \\ y \to \infty}} F_{\xi, \eta}(x, y) = 1$

        \item Восстановление маргинального (частного) распределения: 
        $\lim_{x \to \infty} F_{\xi, \eta}(x, y) = F_\eta(y)$, и наоборот - $\lim_{y \to \infty} F_{\xi, \eta}(x, y) = F_\xi(x)$

        \item $F_{\xi, \eta}(x, y)$ - непрерывна слева по каждому аргументу

        \item $P(x_1 \leq \xi < x_2, y_1 \leq \eta < y_2) = F_{\xi, \eta}(x_2, y_2) - F_{\xi, \eta}(x_2, y_1) - F_{\xi, \eta}(x_1, y_2) + F_{\xi, \eta}(x_1, y_1)$
    \end{enumerate}

    \hyperlink{randomvariablesindependence}{Независимость величин}: Случайные величины $\xi_1, \dots, \xi_n$ независимы в совокупности, если для любого набора Борелевских множеств из
    $\mathcal{B}(\Real^n)$, $B_1, B_2, \dots, B_n$ верно $p(\xi_1 \in B_1, \xi_2 \in B_2, \dots, \xi_n \in B_n) = p(\xi_1 \in B_1) \cdot p(\xi_2 \in B_2) \cdot \dots \cdot p(\xi_n \in B_n)$

    Случайные величины $\xi_1, \xi_2, \dots, \xi_n$ попарно независимы, если независимы любые две из них

    \item Дискретная система двух случайных величин. Закон совместного распределения. Маргинальные распределения.

    \hyperlink{discretesystemoftwovariables}{Дискретная система}: Случайные величины $\xi, \eta$ имеют совместное дискретное распределение, если случайный вектор $(\xi, \eta)$
    принимает не более, чем счетное число значений, то есть существует конечный или счетный набор пар чисел $(x_i, y_i)$, 
    таких что $P(\xi = x_i, \eta = y_i) > 0, \sum_{i, j} P(\xi = x_i, \eta = y_i) = 1$
    
    Таким образом двумерная дискретная случайная величина задается законом распределения - таблице вероятностей

    \begin{tabular}{c|c|c|c|c}
        $\xi \backslash \eta$ & $y_1$ & $y_2$ & $\dots$ & $y_m$ \\
        \hline
        $x_1$ & $p_{11}$ & $p_{12}$ & $\dots$ & $p_{1m}$ \\
        \hline
        $x_2$ & $p_{21}$ & $p_{22}$ & $\dots$ & $p_{2m}$ \\
        \hline
        $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
        \hline
        $x_n$ & $p_{n1}$ & $p_{n2}$ & $\dots$ & $p_{nm}$ \\
    \end{tabular}

    Зная общий закон распределения, можно восстановить частное (маргинальное) распределение по формулам: 

    $p_i = \sum_{j = 1}^m p_{i, j} \qquad q_j = \sum_{i = 1}^n p_{i, j}$

    \item Абсолютно непрерывная система двух случайных величин. Плотность совместного распределения, ее свойства.
    
    \hyperlink{continuoussystemoftwovariables}{Непрерывная система}: Случайные величины $\xi$ и $\eta$ имеют абсолютно непрерывное совместное распределение, если
    $\exists f_{\xi, \eta}(x, y)$, такая что $\forall B \in \mathcal{B}(\Real^2) \ P((\xi, \eta) \in B) = \iint_B f_{\xi, \eta}(x, y) dxdy$

    Функцию $f_{\xi, \eta}(x, y)$ будем называть функцией плотности совместного распределения случайных величин $\xi$ и $\eta$

    \hyperlink{densityfunctionpropertiesincontinuoussystem}{Свойства}: 

    
    \begin{enumerate}
        \item $f_{\xi, \eta}(x, y) \leq 0$
        \item Условие нормировки: $\iint_{\Real^2} f_{\xi, \eta}(x, y) dxdy = 1$
        \item $F_{\xi, \eta} = \int_{-\infty}^x \int_{-\infty}^y f_{\xi, \eta}(x, y) dydx$

        \item $f_{\xi, \eta}(x, y) = \frac{\partial^2 F_{\xi, \eta}(x, y)}{\partial x \partial y}$
        
        \item Если случайные величины $\xi, \eta$ имеют абсолютно непрерывное совместное распределение с плотностью $f(x, y)$, 
        то маргинальное распределение величин $\xi, \eta$ также имеют абсолютно непрерывное распределение
        с плотностями $f_\xi(x) = \int_{-\infty}^\infty f_{\xi, \eta}(x, y) dy, f_\eta(y) = \int_{-\infty}^\infty f_{\xi, \eta}(x, y) dx$

        \item Так как вероятность попадания в Борелевские множества полностью задается функцией распределения, 
        то условие независимости случайных величин эквивалентно следующему:

        $\xi_1, \xi_2, \dots, \xi_n$ независимы, если функция общего распределения распадается в произведение 
        отдельных функцию распределения
    
        $F_{\xi_1, \xi_2, \dots, \xi_n}(x_1, x_2, \dots, x_n) = F_{\xi_1}(x_1) \cdot F_{\xi_2}(x_2) \cdot \dots \cdot F_{\xi_n}(x_n)$

        \item \textit{Равносильное определение}: абсолютно непрерывные случайные величины $\xi_1, \dots, \xi_n$ независимы в совокупности тогда и только тогда, 
        когда плотность совместного распределения $f_{\xi_1, \xi_2, \dots, \xi_n}(x_1, x_2, \dots, x_n) = f_{\xi_1}(x_1) \cdot f_{\xi_2}(x_2) \cdot \dots \cdot f_{\xi_n}(x_n)$
    \end{enumerate}

    \item Функции от двух случайных величин. Теорема о функции распределения. Формула свертки.
    \item Суммы стандартных распределений, устойчивость по суммированию (биномиальное, Пуассона, стандартное нормальное).
    \item Условные распределения и условные математические ожидания. Случаи дискретной и абсолютно непрерывной систем двух случайных величин.
    \item Пространство случайных величин. Скалярное произведение, неравенство Коши-Буняковского-Шварца. 
    \item Условное математическое ожидание как случайная величина, его свойства. Формула полного математического ожидания.
    \item Условная дисперсия. Закон полной дисперсии. Смысл второго слагаемого в разложении дисперсии.
    \item Числовые характеристики зависимости случайных величин. Ковариация, ее свойства. Коэффициент корреляции, его свойства. Корреляция случайных величин.
    \item Характеристическая функция случайной величины, ее свойства. Теорема о непрерывном соответствии (формулировка).
    \item Характеристические функции стандартных распределений (Бернулли, биномиальное, Пуассона, нормальное). Следствия.
    \item Доказательство закона больших чисел Хинчина.
    \item Центральная предельная теорема. Вывод из нее предельной теоремы Муавра-Лапласа. Неравенство Берри-Ессеена (формулировка). 

    \hyperlink{centrallimittheorem}{ЦПТ Ляпунова} \Ths Пусть $\xi_1, \dots, \xi_n, \dots$ - последовательность независимых одинаково распределенных случайных величин
    с конечной дисперсией ($D\xi_1 < \infty$) и $S_n = \sum_{i = 1}^n \xi_i$. Тогда имеет место слабая сходимость:

    \[\frac{S_n - nE\xi_1}{\sqrt{nD\xi_1}} \rightrightarrows N(0, 1)\]


\end{enumerate}
